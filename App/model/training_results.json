{
  "model_name": "roberta-base",
  "training_samples": 99795,
  "validation_samples": 24949,
  "final_accuracy": 0.8357449196360576,
  "final_f1": 0.8315151383052936,
  "final_precision": 0.8393741425713696,
  "final_recall": 0.8357449196360576,
  "training_history": [
    {
      "epoch": 0.032061558191728116,
      "step": 100,
      "loss": 1.3966,
      "grad_norm": 8.724546432495117,
      "learning_rate": 1.0256410256410257e-06
    },
    {
      "epoch": 0.06412311638345623,
      "step": 200,
      "loss": 1.401,
      "grad_norm": 4.963259220123291,
      "learning_rate": 2.094017094017094e-06
    },
    {
      "epoch": 0.09618467457518436,
      "step": 300,
      "loss": 1.3984,
      "grad_norm": 6.656797409057617,
      "learning_rate": 3.1623931623931626e-06
    },
    {
      "epoch": 0.12824623276691247,
      "step": 400,
      "loss": 1.3876,
      "grad_norm": 16.356529235839844,
      "learning_rate": 4.230769230769231e-06
    },
    {
      "epoch": 0.1603077909586406,
      "step": 500,
      "loss": 1.3926,
      "grad_norm": 10.469545364379883,
      "learning_rate": 5.2991452991453e-06
    },
    {
      "epoch": 0.1923693491503687,
      "step": 600,
      "loss": 1.3923,
      "grad_norm": 4.6857709884643555,
      "learning_rate": 6.367521367521368e-06
    },
    {
      "epoch": 0.22443090734209684,
      "step": 700,
      "loss": 1.3878,
      "grad_norm": 4.036665916442871,
      "learning_rate": 7.435897435897437e-06
    },
    {
      "epoch": 0.25649246553382493,
      "step": 800,
      "loss": 1.3779,
      "grad_norm": 8.066911697387695,
      "learning_rate": 8.504273504273505e-06
    },
    {
      "epoch": 0.28855402372555305,
      "step": 900,
      "loss": 1.3228,
      "grad_norm": 17.330570220947266,
      "learning_rate": 9.572649572649575e-06
    },
    {
      "epoch": 0.3206155819172812,
      "step": 1000,
      "loss": 1.2186,
      "grad_norm": 18.584171295166016,
      "learning_rate": 1.0641025641025643e-05
    },
    {
      "epoch": 0.3526771401090093,
      "step": 1100,
      "loss": 1.1588,
      "grad_norm": 19.698139190673828,
      "learning_rate": 1.170940170940171e-05
    },
    {
      "epoch": 0.3847386983007374,
      "step": 1200,
      "loss": 1.0909,
      "grad_norm": 17.64037322998047,
      "learning_rate": 1.2777777777777777e-05
    },
    {
      "epoch": 0.41680025649246555,
      "step": 1300,
      "loss": 1.0674,
      "grad_norm": 19.337900161743164,
      "learning_rate": 1.3846153846153847e-05
    },
    {
      "epoch": 0.44886181468419367,
      "step": 1400,
      "loss": 1.0461,
      "grad_norm": 16.233259201049805,
      "learning_rate": 1.4914529914529916e-05
    },
    {
      "epoch": 0.4809233728759218,
      "step": 1500,
      "loss": 1.0577,
      "grad_norm": 18.808137893676758,
      "learning_rate": 1.5982905982905986e-05
    },
    {
      "epoch": 0.5129849310676499,
      "step": 1600,
      "loss": 1.0225,
      "grad_norm": 21.25715446472168,
      "learning_rate": 1.7051282051282053e-05
    },
    {
      "epoch": 0.545046489259378,
      "step": 1700,
      "loss": 1.0098,
      "grad_norm": 19.467378616333008,
      "learning_rate": 1.8119658119658122e-05
    },
    {
      "epoch": 0.5771080474511061,
      "step": 1800,
      "loss": 0.9884,
      "grad_norm": 19.781936645507812,
      "learning_rate": 1.918803418803419e-05
    },
    {
      "epoch": 0.6091696056428343,
      "step": 1900,
      "loss": 0.9884,
      "grad_norm": 14.871286392211914,
      "learning_rate": 1.997268732929581e-05
    },
    {
      "epoch": 0.6412311638345624,
      "step": 2000,
      "loss": 0.9712,
      "grad_norm": 14.207509994506836,
      "learning_rate": 1.985393658710367e-05
    },
    {
      "epoch": 0.6732927220262904,
      "step": 2100,
      "loss": 0.9729,
      "grad_norm": 19.114498138427734,
      "learning_rate": 1.9735185844911532e-05
    },
    {
      "epoch": 0.7053542802180186,
      "step": 2200,
      "loss": 0.9657,
      "grad_norm": 12.219827651977539,
      "learning_rate": 1.9616435102719394e-05
    },
    {
      "epoch": 0.7374158384097467,
      "step": 2300,
      "loss": 0.9284,
      "grad_norm": 21.193405151367188,
      "learning_rate": 1.9497684360527256e-05
    },
    {
      "epoch": 0.7694773966014749,
      "step": 2400,
      "loss": 0.9517,
      "grad_norm": 13.729451179504395,
      "learning_rate": 1.9378933618335117e-05
    },
    {
      "epoch": 0.8015389547932029,
      "step": 2500,
      "loss": 0.946,
      "grad_norm": 17.661592483520508,
      "learning_rate": 1.9260182876142976e-05
    },
    {
      "epoch": 0.8336005129849311,
      "step": 2600,
      "loss": 0.9265,
      "grad_norm": 18.679079055786133,
      "learning_rate": 1.9141432133950837e-05
    },
    {
      "epoch": 0.8656620711766592,
      "step": 2700,
      "loss": 0.9004,
      "grad_norm": 13.7598295211792,
      "learning_rate": 1.90226813917587e-05
    },
    {
      "epoch": 0.8977236293683873,
      "step": 2800,
      "loss": 0.9421,
      "grad_norm": 14.424457550048828,
      "learning_rate": 1.890393064956656e-05
    },
    {
      "epoch": 0.9297851875601154,
      "step": 2900,
      "loss": 0.889,
      "grad_norm": 12.651107788085938,
      "learning_rate": 1.8785179907374423e-05
    },
    {
      "epoch": 0.9618467457518436,
      "step": 3000,
      "loss": 0.8876,
      "grad_norm": 17.75577163696289,
      "learning_rate": 1.8666429165182284e-05
    },
    {
      "epoch": 0.9939083039435717,
      "step": 3100,
      "loss": 0.9067,
      "grad_norm": 19.13780975341797,
      "learning_rate": 1.8547678422990146e-05
    },
    {
      "epoch": 1.0,
      "step": 3119,
      "eval_loss": 0.9446002840995789,
      "eval_accuracy": 0.6572207302897912,
      "eval_f1": 0.6459442286198662,
      "eval_precision": 0.6781808503043664,
      "eval_recall": 0.6572207302897912,
      "eval_runtime": 36.3536,
      "eval_samples_per_second": 686.287,
      "eval_steps_per_second": 10.728
    },
    {
      "epoch": 1.0259698621352997,
      "step": 3200,
      "loss": 0.8579,
      "grad_norm": 17.479990005493164,
      "learning_rate": 1.8428927680798004e-05
    },
    {
      "epoch": 1.0580314203270278,
      "step": 3300,
      "loss": 0.8726,
      "grad_norm": 24.380308151245117,
      "learning_rate": 1.831017693860587e-05
    },
    {
      "epoch": 1.090092978518756,
      "step": 3400,
      "loss": 0.8594,
      "grad_norm": 18.53683853149414,
      "learning_rate": 1.8191426196413728e-05
    },
    {
      "epoch": 1.1221545367104842,
      "step": 3500,
      "loss": 0.8693,
      "grad_norm": 16.714136123657227,
      "learning_rate": 1.807267545422159e-05
    },
    {
      "epoch": 1.1542160949022122,
      "step": 3600,
      "loss": 0.8684,
      "grad_norm": 15.521536827087402,
      "learning_rate": 1.7955112219451373e-05
    },
    {
      "epoch": 1.1862776530939403,
      "step": 3700,
      "loss": 0.8486,
      "grad_norm": 17.56545066833496,
      "learning_rate": 1.7836361477259234e-05
    },
    {
      "epoch": 1.2183392112856686,
      "step": 3800,
      "loss": 0.8514,
      "grad_norm": 15.82935619354248,
      "learning_rate": 1.7717610735067096e-05
    },
    {
      "epoch": 1.2504007694773966,
      "step": 3900,
      "loss": 0.8335,
      "grad_norm": 15.476391792297363,
      "learning_rate": 1.7598859992874958e-05
    },
    {
      "epoch": 1.2824623276691247,
      "step": 4000,
      "loss": 0.8405,
      "grad_norm": 19.369062423706055,
      "learning_rate": 1.7480109250682816e-05
    },
    {
      "epoch": 1.3145238858608528,
      "step": 4100,
      "loss": 0.8329,
      "grad_norm": 18.511947631835938,
      "learning_rate": 1.736135850849068e-05
    },
    {
      "epoch": 1.346585444052581,
      "step": 4200,
      "loss": 0.8392,
      "grad_norm": 19.163463592529297,
      "learning_rate": 1.724260776629854e-05
    },
    {
      "epoch": 1.3786470022443091,
      "step": 4300,
      "loss": 0.8232,
      "grad_norm": 16.685184478759766,
      "learning_rate": 1.71238570241064e-05
    },
    {
      "epoch": 1.4107085604360372,
      "step": 4400,
      "loss": 0.8044,
      "grad_norm": 16.71450424194336,
      "learning_rate": 1.7005106281914263e-05
    },
    {
      "epoch": 1.4427701186277653,
      "step": 4500,
      "loss": 0.8181,
      "grad_norm": 14.309786796569824,
      "learning_rate": 1.6886355539722125e-05
    },
    {
      "epoch": 1.4748316768194933,
      "step": 4600,
      "loss": 0.8447,
      "grad_norm": 16.806703567504883,
      "learning_rate": 1.6767604797529987e-05
    },
    {
      "epoch": 1.5068932350112214,
      "step": 4700,
      "loss": 0.8361,
      "grad_norm": 15.691202163696289,
      "learning_rate": 1.6648854055337845e-05
    },
    {
      "epoch": 1.5389547932029497,
      "step": 4800,
      "loss": 0.7955,
      "grad_norm": 20.33296775817871,
      "learning_rate": 1.653010331314571e-05
    },
    {
      "epoch": 1.5710163513946778,
      "step": 4900,
      "loss": 0.7869,
      "grad_norm": 19.854568481445312,
      "learning_rate": 1.641135257095357e-05
    },
    {
      "epoch": 1.603077909586406,
      "step": 5000,
      "loss": 0.7954,
      "grad_norm": 12.821571350097656,
      "learning_rate": 1.6292601828761433e-05
    },
    {
      "epoch": 1.6351394677781341,
      "step": 5100,
      "loss": 0.8093,
      "grad_norm": 14.892667770385742,
      "learning_rate": 1.6173851086569292e-05
    },
    {
      "epoch": 1.6672010259698622,
      "step": 5200,
      "loss": 0.7988,
      "grad_norm": 16.489913940429688,
      "learning_rate": 1.6055100344377153e-05
    },
    {
      "epoch": 1.6992625841615903,
      "step": 5300,
      "loss": 0.7584,
      "grad_norm": 17.480472564697266,
      "learning_rate": 1.5936349602185015e-05
    },
    {
      "epoch": 1.7313241423533183,
      "step": 5400,
      "loss": 0.8092,
      "grad_norm": 24.771038055419922,
      "learning_rate": 1.5817598859992877e-05
    },
    {
      "epoch": 1.7633857005450464,
      "step": 5500,
      "loss": 0.8091,
      "grad_norm": 17.918888092041016,
      "learning_rate": 1.569884811780074e-05
    },
    {
      "epoch": 1.7954472587367745,
      "step": 5600,
      "loss": 0.7866,
      "grad_norm": 16.196456909179688,
      "learning_rate": 1.5580097375608597e-05
    },
    {
      "epoch": 1.8275088169285028,
      "step": 5700,
      "loss": 0.7595,
      "grad_norm": 12.845401763916016,
      "learning_rate": 1.5461346633416462e-05
    },
    {
      "epoch": 1.8595703751202308,
      "step": 5800,
      "loss": 0.761,
      "grad_norm": 13.107937812805176,
      "learning_rate": 1.534259589122432e-05
    },
    {
      "epoch": 1.8916319333119591,
      "step": 5900,
      "loss": 0.7575,
      "grad_norm": 16.16660499572754,
      "learning_rate": 1.5223845149032184e-05
    },
    {
      "epoch": 1.9236934915036872,
      "step": 6000,
      "loss": 0.7804,
      "grad_norm": 17.230165481567383,
      "learning_rate": 1.5105094406840044e-05
    },
    {
      "epoch": 1.9557550496954152,
      "step": 6100,
      "loss": 0.761,
      "grad_norm": 21.08420753479004,
      "learning_rate": 1.4986343664647904e-05
    },
    {
      "epoch": 1.9878166078871433,
      "step": 6200,
      "loss": 0.76,
      "grad_norm": 21.648509979248047,
      "learning_rate": 1.4867592922455767e-05
    },
    {
      "epoch": 2.0,
      "step": 6238,
      "eval_loss": 0.7791984677314758,
      "eval_accuracy": 0.7223936831135517,
      "eval_f1": 0.7156022117072802,
      "eval_precision": 0.7319147069931339,
      "eval_recall": 0.7223936831135517,
      "eval_runtime": 36.3071,
      "eval_samples_per_second": 687.166,
      "eval_steps_per_second": 10.742
    },
    {
      "epoch": 2.0198781660788714,
      "step": 6300,
      "loss": 0.724,
      "grad_norm": 15.15322494506836,
      "learning_rate": 1.4748842180263627e-05
    },
    {
      "epoch": 2.0519397242705995,
      "step": 6400,
      "loss": 0.7284,
      "grad_norm": 14.54430103302002,
      "learning_rate": 1.4630091438071489e-05
    },
    {
      "epoch": 2.0840012824623275,
      "step": 6500,
      "loss": 0.7428,
      "grad_norm": 13.599609375,
      "learning_rate": 1.4511340695879351e-05
    },
    {
      "epoch": 2.1160628406540556,
      "step": 6600,
      "loss": 0.736,
      "grad_norm": 18.706575393676758,
      "learning_rate": 1.4392589953687213e-05
    },
    {
      "epoch": 2.148124398845784,
      "step": 6700,
      "loss": 0.7643,
      "grad_norm": 17.760530471801758,
      "learning_rate": 1.4273839211495073e-05
    },
    {
      "epoch": 2.180185957037512,
      "step": 6800,
      "loss": 0.7407,
      "grad_norm": 13.15821647644043,
      "learning_rate": 1.4155088469302933e-05
    },
    {
      "epoch": 2.2122475152292402,
      "step": 6900,
      "loss": 0.7117,
      "grad_norm": 20.300722122192383,
      "learning_rate": 1.4036337727110796e-05
    },
    {
      "epoch": 2.2443090734209683,
      "step": 7000,
      "loss": 0.7096,
      "grad_norm": 13.203348159790039,
      "learning_rate": 1.3917586984918656e-05
    },
    {
      "epoch": 2.2763706316126964,
      "step": 7100,
      "loss": 0.7133,
      "grad_norm": 16.981969833374023,
      "learning_rate": 1.379883624272652e-05
    },
    {
      "epoch": 2.3084321898044244,
      "step": 7200,
      "loss": 0.7146,
      "grad_norm": 24.18280029296875,
      "learning_rate": 1.368008550053438e-05
    },
    {
      "epoch": 2.3404937479961525,
      "step": 7300,
      "loss": 0.7132,
      "grad_norm": 17.516128540039062,
      "learning_rate": 1.3561334758342241e-05
    },
    {
      "epoch": 2.3725553061878806,
      "step": 7400,
      "loss": 0.7147,
      "grad_norm": 16.04891586303711,
      "learning_rate": 1.3442584016150101e-05
    },
    {
      "epoch": 2.4046168643796086,
      "step": 7500,
      "loss": 0.7415,
      "grad_norm": 19.155141830444336,
      "learning_rate": 1.3323833273957963e-05
    },
    {
      "epoch": 2.436678422571337,
      "step": 7600,
      "loss": 0.7012,
      "grad_norm": 14.81550121307373,
      "learning_rate": 1.3205082531765825e-05
    },
    {
      "epoch": 2.4687399807630652,
      "step": 7700,
      "loss": 0.6941,
      "grad_norm": 19.86137580871582,
      "learning_rate": 1.3086331789573685e-05
    },
    {
      "epoch": 2.5008015389547933,
      "step": 7800,
      "loss": 0.7044,
      "grad_norm": 15.68700885772705,
      "learning_rate": 1.2967581047381548e-05
    },
    {
      "epoch": 2.5328630971465214,
      "step": 7900,
      "loss": 0.6821,
      "grad_norm": 24.497108459472656,
      "learning_rate": 1.2848830305189408e-05
    },
    {
      "epoch": 2.5649246553382494,
      "step": 8000,
      "loss": 0.6805,
      "grad_norm": 19.96783447265625,
      "learning_rate": 1.2731267070419191e-05
    },
    {
      "epoch": 2.5969862135299775,
      "step": 8100,
      "loss": 0.6808,
      "grad_norm": 23.853374481201172,
      "learning_rate": 1.2612516328227053e-05
    },
    {
      "epoch": 2.6290477717217056,
      "step": 8200,
      "loss": 0.6913,
      "grad_norm": 17.04984474182129,
      "learning_rate": 1.2493765586034913e-05
    },
    {
      "epoch": 2.6611093299134336,
      "step": 8300,
      "loss": 0.7064,
      "grad_norm": 17.681743621826172,
      "learning_rate": 1.2375014843842775e-05
    },
    {
      "epoch": 2.693170888105162,
      "step": 8400,
      "loss": 0.69,
      "grad_norm": 13.415947914123535,
      "learning_rate": 1.2256264101650636e-05
    },
    {
      "epoch": 2.72523244629689,
      "step": 8500,
      "loss": 0.6807,
      "grad_norm": 17.3226261138916,
      "learning_rate": 1.2137513359458497e-05
    },
    {
      "epoch": 2.7572940044886183,
      "step": 8600,
      "loss": 0.6752,
      "grad_norm": 21.265165328979492,
      "learning_rate": 1.201876261726636e-05
    },
    {
      "epoch": 2.7893555626803463,
      "step": 8700,
      "loss": 0.6692,
      "grad_norm": 15.963874816894531,
      "learning_rate": 1.190001187507422e-05
    },
    {
      "epoch": 2.8214171208720744,
      "step": 8800,
      "loss": 0.6727,
      "grad_norm": 20.7927303314209,
      "learning_rate": 1.1781261132882082e-05
    },
    {
      "epoch": 2.8534786790638025,
      "step": 8900,
      "loss": 0.6743,
      "grad_norm": 16.086223602294922,
      "learning_rate": 1.1662510390689943e-05
    },
    {
      "epoch": 2.8855402372555305,
      "step": 9000,
      "loss": 0.665,
      "grad_norm": 31.375001907348633,
      "learning_rate": 1.1543759648497803e-05
    },
    {
      "epoch": 2.9176017954472586,
      "step": 9100,
      "loss": 0.6683,
      "grad_norm": 17.675012588500977,
      "learning_rate": 1.1425008906305665e-05
    },
    {
      "epoch": 2.9496633536389867,
      "step": 9200,
      "loss": 0.6452,
      "grad_norm": 25.596172332763672,
      "learning_rate": 1.1306258164113525e-05
    },
    {
      "epoch": 2.9817249118307148,
      "step": 9300,
      "loss": 0.672,
      "grad_norm": 19.33863067626953,
      "learning_rate": 1.1187507421921389e-05
    },
    {
      "epoch": 3.0,
      "step": 9357,
      "eval_loss": 0.6928820013999939,
      "eval_accuracy": 0.7616738145817468,
      "eval_f1": 0.7555682045019517,
      "eval_precision": 0.7714086688340869,
      "eval_recall": 0.7616738145817468,
      "eval_runtime": 36.299,
      "eval_samples_per_second": 687.319,
      "eval_steps_per_second": 10.744
    },
    {
      "epoch": 3.0137864700224433,
      "step": 9400,
      "loss": 0.6104,
      "grad_norm": 18.433921813964844,
      "learning_rate": 1.1068756679729249e-05
    },
    {
      "epoch": 3.0458480282141713,
      "step": 9500,
      "loss": 0.6248,
      "grad_norm": 25.957096099853516,
      "learning_rate": 1.0950005937537112e-05
    },
    {
      "epoch": 3.0779095864058994,
      "step": 9600,
      "loss": 0.6332,
      "grad_norm": 19.282861709594727,
      "learning_rate": 1.0831255195344972e-05
    },
    {
      "epoch": 3.1099711445976275,
      "step": 9700,
      "loss": 0.6166,
      "grad_norm": 16.147472381591797,
      "learning_rate": 1.0712504453152832e-05
    },
    {
      "epoch": 3.1420327027893555,
      "step": 9800,
      "loss": 0.627,
      "grad_norm": 18.807796478271484,
      "learning_rate": 1.0593753710960694e-05
    },
    {
      "epoch": 3.1740942609810836,
      "step": 9900,
      "loss": 0.6251,
      "grad_norm": 19.955503463745117,
      "learning_rate": 1.0475002968768556e-05
    },
    {
      "epoch": 3.2061558191728117,
      "step": 10000,
      "loss": 0.6396,
      "grad_norm": 21.001577377319336,
      "learning_rate": 1.0356252226576417e-05
    },
    {
      "epoch": 3.2382173773645397,
      "step": 10100,
      "loss": 0.5918,
      "grad_norm": 18.43570327758789,
      "learning_rate": 1.0237501484384277e-05
    },
    {
      "epoch": 3.2702789355562683,
      "step": 10200,
      "loss": 0.6232,
      "grad_norm": 23.72273826599121,
      "learning_rate": 1.011875074219214e-05
    },
    {
      "epoch": 3.3023404937479963,
      "step": 10300,
      "loss": 0.627,
      "grad_norm": 19.369596481323242,
      "learning_rate": 1e-05
    },
    {
      "epoch": 3.3344020519397244,
      "step": 10400,
      "loss": 0.6234,
      "grad_norm": 19.661069869995117,
      "learning_rate": 9.881249257807863e-06
    },
    {
      "epoch": 3.3664636101314525,
      "step": 10500,
      "loss": 0.6128,
      "grad_norm": 21.378894805908203,
      "learning_rate": 9.762498515615724e-06
    },
    {
      "epoch": 3.3985251683231805,
      "step": 10600,
      "loss": 0.5829,
      "grad_norm": 19.06623077392578,
      "learning_rate": 9.643747773423584e-06
    },
    {
      "epoch": 3.4305867265149086,
      "step": 10700,
      "loss": 0.5966,
      "grad_norm": 12.530254364013672,
      "learning_rate": 9.524997031231446e-06
    },
    {
      "epoch": 3.4626482847066367,
      "step": 10800,
      "loss": 0.598,
      "grad_norm": 20.738256454467773,
      "learning_rate": 9.406246289039308e-06
    },
    {
      "epoch": 3.4947098428983647,
      "step": 10900,
      "loss": 0.6094,
      "grad_norm": 17.97385025024414,
      "learning_rate": 9.287495546847168e-06
    },
    {
      "epoch": 3.526771401090093,
      "step": 11000,
      "loss": 0.5942,
      "grad_norm": 17.537939071655273,
      "learning_rate": 9.16874480465503e-06
    },
    {
      "epoch": 3.558832959281821,
      "step": 11100,
      "loss": 0.5892,
      "grad_norm": 23.09366226196289,
      "learning_rate": 9.049994062462891e-06
    },
    {
      "epoch": 3.5908945174735494,
      "step": 11200,
      "loss": 0.5906,
      "grad_norm": 20.402196884155273,
      "learning_rate": 8.931243320270753e-06
    },
    {
      "epoch": 3.6229560756652774,
      "step": 11300,
      "loss": 0.5704,
      "grad_norm": 18.355037689208984,
      "learning_rate": 8.813680085500536e-06
    },
    {
      "epoch": 3.6550176338570055,
      "step": 11400,
      "loss": 0.5917,
      "grad_norm": 16.50718116760254,
      "learning_rate": 8.694929343308396e-06
    },
    {
      "epoch": 3.6870791920487336,
      "step": 11500,
      "loss": 0.6149,
      "grad_norm": 20.553041458129883,
      "learning_rate": 8.576178601116258e-06
    },
    {
      "epoch": 3.7191407502404616,
      "step": 11600,
      "loss": 0.567,
      "grad_norm": 21.16826057434082,
      "learning_rate": 8.45742785892412e-06
    },
    {
      "epoch": 3.7512023084321897,
      "step": 11700,
      "loss": 0.603,
      "grad_norm": 23.986608505249023,
      "learning_rate": 8.33867711673198e-06
    },
    {
      "epoch": 3.783263866623918,
      "step": 11800,
      "loss": 0.5632,
      "grad_norm": 25.22723388671875,
      "learning_rate": 8.219926374539841e-06
    },
    {
      "epoch": 3.8153254248156463,
      "step": 11900,
      "loss": 0.5476,
      "grad_norm": 21.038850784301758,
      "learning_rate": 8.101175632347703e-06
    },
    {
      "epoch": 3.8473869830073744,
      "step": 12000,
      "loss": 0.5535,
      "grad_norm": 20.004440307617188,
      "learning_rate": 7.982424890155565e-06
    },
    {
      "epoch": 3.8794485411991024,
      "step": 12100,
      "loss": 0.5625,
      "grad_norm": 19.61957359313965,
      "learning_rate": 7.863674147963425e-06
    },
    {
      "epoch": 3.9115100993908305,
      "step": 12200,
      "loss": 0.5633,
      "grad_norm": 12.270755767822266,
      "learning_rate": 7.744923405771286e-06
    },
    {
      "epoch": 3.9435716575825586,
      "step": 12300,
      "loss": 0.5479,
      "grad_norm": 18.881486892700195,
      "learning_rate": 7.626172663579148e-06
    },
    {
      "epoch": 3.9756332157742866,
      "step": 12400,
      "loss": 0.556,
      "grad_norm": 24.281686782836914,
      "learning_rate": 7.507421921387009e-06
    },
    {
      "epoch": 4.0,
      "step": 12476,
      "eval_loss": 0.6384605169296265,
      "eval_accuracy": 0.7815142891498658,
      "eval_f1": 0.7756411907092652,
      "eval_precision": 0.7936233801556621,
      "eval_recall": 0.7815142891498658,
      "eval_runtime": 36.2749,
      "eval_samples_per_second": 687.777,
      "eval_steps_per_second": 10.751
    },
    {
      "epoch": 4.007694773966015,
      "step": 12500,
      "loss": 0.5492,
      "grad_norm": 16.120891571044922,
      "learning_rate": 7.388671179194871e-06
    },
    {
      "epoch": 4.039756332157743,
      "step": 12600,
      "loss": 0.5356,
      "grad_norm": 23.722637176513672,
      "learning_rate": 7.2699204370027325e-06
    },
    {
      "epoch": 4.071817890349471,
      "step": 12700,
      "loss": 0.5589,
      "grad_norm": 21.940853118896484,
      "learning_rate": 7.151169694810593e-06
    },
    {
      "epoch": 4.103879448541199,
      "step": 12800,
      "loss": 0.5235,
      "grad_norm": 27.97635269165039,
      "learning_rate": 7.032418952618455e-06
    },
    {
      "epoch": 4.135941006732927,
      "step": 12900,
      "loss": 0.5443,
      "grad_norm": 19.858917236328125,
      "learning_rate": 6.913668210426315e-06
    },
    {
      "epoch": 4.168002564924655,
      "step": 13000,
      "loss": 0.52,
      "grad_norm": 27.830324172973633,
      "learning_rate": 6.794917468234177e-06
    },
    {
      "epoch": 4.200064123116383,
      "step": 13100,
      "loss": 0.5428,
      "grad_norm": 27.92917823791504,
      "learning_rate": 6.676166726042039e-06
    },
    {
      "epoch": 4.232125681308111,
      "step": 13200,
      "loss": 0.5239,
      "grad_norm": 23.896827697753906,
      "learning_rate": 6.5574159838498995e-06
    },
    {
      "epoch": 4.26418723949984,
      "step": 13300,
      "loss": 0.5315,
      "grad_norm": 32.122772216796875,
      "learning_rate": 6.438665241657761e-06
    },
    {
      "epoch": 4.296248797691568,
      "step": 13400,
      "loss": 0.5092,
      "grad_norm": 29.638093948364258,
      "learning_rate": 6.319914499465623e-06
    },
    {
      "epoch": 4.328310355883296,
      "step": 13500,
      "loss": 0.5361,
      "grad_norm": 23.31256866455078,
      "learning_rate": 6.201163757273484e-06
    },
    {
      "epoch": 4.360371914075024,
      "step": 13600,
      "loss": 0.5293,
      "grad_norm": 20.82207489013672,
      "learning_rate": 6.082413015081345e-06
    },
    {
      "epoch": 4.392433472266752,
      "step": 13700,
      "loss": 0.5055,
      "grad_norm": 22.515928268432617,
      "learning_rate": 5.9636622728892056e-06
    },
    {
      "epoch": 4.4244950304584805,
      "step": 13800,
      "loss": 0.5402,
      "grad_norm": 18.03291893005371,
      "learning_rate": 5.844911530697067e-06
    },
    {
      "epoch": 4.4565565886502085,
      "step": 13900,
      "loss": 0.5117,
      "grad_norm": 24.857723236083984,
      "learning_rate": 5.726160788504929e-06
    },
    {
      "epoch": 4.488618146841937,
      "step": 14000,
      "loss": 0.4912,
      "grad_norm": 36.48815155029297,
      "learning_rate": 5.60741004631279e-06
    },
    {
      "epoch": 4.520679705033665,
      "step": 14100,
      "loss": 0.5163,
      "grad_norm": 25.6309871673584,
      "learning_rate": 5.488659304120652e-06
    },
    {
      "epoch": 4.552741263225393,
      "step": 14200,
      "loss": 0.5332,
      "grad_norm": 28.02971076965332,
      "learning_rate": 5.369908561928513e-06
    },
    {
      "epoch": 4.584802821417121,
      "step": 14300,
      "loss": 0.5119,
      "grad_norm": 23.925365447998047,
      "learning_rate": 5.251157819736373e-06
    },
    {
      "epoch": 4.616864379608849,
      "step": 14400,
      "loss": 0.5075,
      "grad_norm": 25.880590438842773,
      "learning_rate": 5.132407077544235e-06
    },
    {
      "epoch": 4.648925937800577,
      "step": 14500,
      "loss": 0.5155,
      "grad_norm": 18.43229866027832,
      "learning_rate": 5.013656335352096e-06
    },
    {
      "epoch": 4.680987495992305,
      "step": 14600,
      "loss": 0.5058,
      "grad_norm": 24.433536529541016,
      "learning_rate": 4.894905593159958e-06
    },
    {
      "epoch": 4.713049054184033,
      "step": 14700,
      "loss": 0.5124,
      "grad_norm": 17.667654037475586,
      "learning_rate": 4.7761548509678194e-06
    },
    {
      "epoch": 4.745110612375761,
      "step": 14800,
      "loss": 0.4943,
      "grad_norm": 30.99388313293457,
      "learning_rate": 4.65740410877568e-06
    },
    {
      "epoch": 4.777172170567489,
      "step": 14900,
      "loss": 0.4923,
      "grad_norm": 19.225019454956055,
      "learning_rate": 4.538653366583541e-06
    },
    {
      "epoch": 4.809233728759217,
      "step": 15000,
      "loss": 0.494,
      "grad_norm": 21.79709815979004,
      "learning_rate": 4.419902624391403e-06
    },
    {
      "epoch": 4.841295286950945,
      "step": 15100,
      "loss": 0.4949,
      "grad_norm": 27.27846336364746,
      "learning_rate": 4.301151882199265e-06
    },
    {
      "epoch": 4.873356845142674,
      "step": 15200,
      "loss": 0.4887,
      "grad_norm": 28.891279220581055,
      "learning_rate": 4.1824011400071255e-06
    },
    {
      "epoch": 4.905418403334402,
      "step": 15300,
      "loss": 0.4864,
      "grad_norm": 16.327035903930664,
      "learning_rate": 4.063650397814986e-06
    },
    {
      "epoch": 4.9374799615261304,
      "step": 15400,
      "loss": 0.5096,
      "grad_norm": 17.510271072387695,
      "learning_rate": 3.944899655622848e-06
    },
    {
      "epoch": 4.9695415197178585,
      "step": 15500,
      "loss": 0.5104,
      "grad_norm": 20.139432907104492,
      "learning_rate": 3.82614891343071e-06
    },
    {
      "epoch": 5.0,
      "step": 15595,
      "eval_loss": 0.5249834656715393,
      "eval_accuracy": 0.8236803078279691,
      "eval_f1": 0.8199514094361183,
      "eval_precision": 0.8277827317868994,
      "eval_recall": 0.8236803078279691,
      "eval_runtime": 36.4858,
      "eval_samples_per_second": 683.8,
      "eval_steps_per_second": 10.689
    },
    {
      "epoch": 5.001603077909587,
      "step": 15600,
      "loss": 0.4613,
      "grad_norm": 15.218478202819824,
      "learning_rate": 3.7073981712385703e-06
    },
    {
      "epoch": 5.033664636101315,
      "step": 15700,
      "loss": 0.4704,
      "grad_norm": 19.811983108520508,
      "learning_rate": 3.5886474290464316e-06
    },
    {
      "epoch": 5.065726194293043,
      "step": 15800,
      "loss": 0.4667,
      "grad_norm": 21.215715408325195,
      "learning_rate": 3.4698966868542934e-06
    },
    {
      "epoch": 5.097787752484771,
      "step": 15900,
      "loss": 0.4591,
      "grad_norm": 31.91071891784668,
      "learning_rate": 3.3511459446621542e-06
    },
    {
      "epoch": 5.129849310676499,
      "step": 16000,
      "loss": 0.4697,
      "grad_norm": 38.294944763183594,
      "learning_rate": 3.2323952024700155e-06
    },
    {
      "epoch": 5.161910868868227,
      "step": 16100,
      "loss": 0.4548,
      "grad_norm": 22.45925521850586,
      "learning_rate": 3.113644460277877e-06
    },
    {
      "epoch": 5.193972427059955,
      "step": 16200,
      "loss": 0.4624,
      "grad_norm": 21.53580665588379,
      "learning_rate": 2.9948937180857386e-06
    },
    {
      "epoch": 5.226033985251683,
      "step": 16300,
      "loss": 0.4612,
      "grad_norm": 21.460514068603516,
      "learning_rate": 2.8761429758935994e-06
    },
    {
      "epoch": 5.258095543443411,
      "step": 16400,
      "loss": 0.4716,
      "grad_norm": 21.25448226928711,
      "learning_rate": 2.758579741123382e-06
    },
    {
      "epoch": 5.290157101635139,
      "step": 16500,
      "loss": 0.463,
      "grad_norm": 17.8934268951416,
      "learning_rate": 2.6398289989312438e-06
    },
    {
      "epoch": 5.322218659826867,
      "step": 16600,
      "loss": 0.4592,
      "grad_norm": 33.418155670166016,
      "learning_rate": 2.5210782567391046e-06
    },
    {
      "epoch": 5.354280218018595,
      "step": 16700,
      "loss": 0.4713,
      "grad_norm": 27.995450973510742,
      "learning_rate": 2.402327514546966e-06
    },
    {
      "epoch": 5.386341776210324,
      "step": 16800,
      "loss": 0.4808,
      "grad_norm": 25.73974609375,
      "learning_rate": 2.2835767723548272e-06
    },
    {
      "epoch": 5.418403334402052,
      "step": 16900,
      "loss": 0.4709,
      "grad_norm": 27.538864135742188,
      "learning_rate": 2.1648260301626885e-06
    },
    {
      "epoch": 5.45046489259378,
      "step": 17000,
      "loss": 0.4422,
      "grad_norm": 9.545526504516602,
      "learning_rate": 2.04607528797055e-06
    },
    {
      "epoch": 5.4825264507855085,
      "step": 17100,
      "loss": 0.4578,
      "grad_norm": 23.97918128967285,
      "learning_rate": 1.927324545778411e-06
    },
    {
      "epoch": 5.5145880089772366,
      "step": 17200,
      "loss": 0.4772,
      "grad_norm": 25.2814884185791,
      "learning_rate": 1.8085738035862727e-06
    },
    {
      "epoch": 5.546649567168965,
      "step": 17300,
      "loss": 0.4499,
      "grad_norm": 35.26226043701172,
      "learning_rate": 1.6898230613941338e-06
    },
    {
      "epoch": 5.578711125360693,
      "step": 17400,
      "loss": 0.4713,
      "grad_norm": 38.55498123168945,
      "learning_rate": 1.5710723192019953e-06
    },
    {
      "epoch": 5.610772683552421,
      "step": 17500,
      "loss": 0.4499,
      "grad_norm": 21.49944305419922,
      "learning_rate": 1.4523215770098564e-06
    },
    {
      "epoch": 5.642834241744149,
      "step": 17600,
      "loss": 0.4583,
      "grad_norm": 11.674972534179688,
      "learning_rate": 1.3335708348177177e-06
    },
    {
      "epoch": 5.674895799935877,
      "step": 17700,
      "loss": 0.4547,
      "grad_norm": 26.321561813354492,
      "learning_rate": 1.214820092625579e-06
    },
    {
      "epoch": 5.706957358127605,
      "step": 17800,
      "loss": 0.4558,
      "grad_norm": 17.56026268005371,
      "learning_rate": 1.0960693504334403e-06
    },
    {
      "epoch": 5.739018916319333,
      "step": 17900,
      "loss": 0.4698,
      "grad_norm": 30.94911003112793,
      "learning_rate": 9.773186082413016e-07
    },
    {
      "epoch": 5.771080474511061,
      "step": 18000,
      "loss": 0.449,
      "grad_norm": 25.933094024658203,
      "learning_rate": 8.585678660491628e-07
    },
    {
      "epoch": 5.803142032702789,
      "step": 18100,
      "loss": 0.4354,
      "grad_norm": 20.117372512817383,
      "learning_rate": 7.398171238570241e-07
    },
    {
      "epoch": 5.835203590894517,
      "step": 18200,
      "loss": 0.4255,
      "grad_norm": 11.033116340637207,
      "learning_rate": 6.210663816648855e-07
    },
    {
      "epoch": 5.867265149086245,
      "step": 18300,
      "loss": 0.4757,
      "grad_norm": 32.00569534301758,
      "learning_rate": 5.023156394727467e-07
    },
    {
      "epoch": 5.899326707277973,
      "step": 18400,
      "loss": 0.4465,
      "grad_norm": 50.82761764526367,
      "learning_rate": 3.8356489728060804e-07
    },
    {
      "epoch": 5.931388265469701,
      "step": 18500,
      "loss": 0.4622,
      "grad_norm": 23.675615310668945,
      "learning_rate": 2.6481415508846935e-07
    },
    {
      "epoch": 5.9634498236614295,
      "step": 18600,
      "loss": 0.4419,
      "grad_norm": 32.417049407958984,
      "learning_rate": 1.4606341289633062e-07
    },
    {
      "epoch": 5.995511381853158,
      "step": 18700,
      "loss": 0.4489,
      "grad_norm": 25.12335205078125,
      "learning_rate": 2.850017812611329e-08
    },
    {
      "epoch": 6.0,
      "step": 18714,
      "eval_loss": 0.496837854385376,
      "eval_accuracy": 0.8357449196360576,
      "eval_f1": 0.8315151383052936,
      "eval_precision": 0.8393741425713696,
      "eval_recall": 0.8357449196360576,
      "eval_runtime": 36.4312,
      "eval_samples_per_second": 684.825,
      "eval_steps_per_second": 10.705
    },
    {
      "epoch": 6.0,
      "step": 18714,
      "train_runtime": 5642.9034,
      "train_samples_per_second": 106.11,
      "train_steps_per_second": 3.316,
      "total_flos": 3.938645891202048e+16,
      "train_loss": 0.6971802612623497
    }
  ],
  "classification_report": {
    "no_distress": {
      "precision": 0.8901283940223111,
      "recall": 0.6780503447170114,
      "f1-score": 0.7697488168911539,
      "support": 6237.0
    },
    "mild": {
      "precision": 0.8156956004756243,
      "recall": 0.7699214365881033,
      "f1-score": 0.792147806004619,
      "support": 6237.0
    },
    "moderate": {
      "precision": 0.8235208181154127,
      "recall": 0.903655017633857,
      "f1-score": 0.8617289612474203,
      "support": 6238.0
    },
    "severe": {
      "precision": 0.828154299491026,
      "recall": 0.9913419913419913,
      "f1-score": 0.9024301247901919,
      "support": 6237.0
    },
    "accuracy": 0.8357449196360576,
    "macro avg": {
      "precision": 0.8393747780260936,
      "recall": 0.8357421975702408,
      "f1-score": 0.8315139272333463,
      "support": 24949.0
    },
    "weighted avg": {
      "precision": 0.8393741425713696,
      "recall": 0.8357449196360576,
      "f1-score": 0.8315151383052936,
      "support": 24949.0
    }
  },
  "confusion_matrix": [
    [
      4229,
      845,
      782,
      381
    ],
    [
      417,
      4802,
      405,
      613
    ],
    [
      93,
      219,
      5637,
      289
    ],
    [
      12,
      21,
      21,
      6183
    ]
  ],
  "label_mapping": {
    "label2id": {
      "no_distress": 0,
      "mild": 1,
      "moderate": 2,
      "severe": 3
    },
    "id2label": {
      "0": "no_distress",
      "1": "mild",
      "2": "moderate",
      "3": "severe"
    }
  },
  "training_config": {
    "learning_rate": 2e-05,
    "batch_size": 16,
    "epochs": 6,
    "weight_decay": 0.01
  }
}